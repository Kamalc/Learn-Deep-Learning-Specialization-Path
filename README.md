# Learn-Deep-Learning-Specialization-Path
# C# Check List
## [01.Neural Networks and Deep Learning](https://www.coursera.org/learn/neural-networks-deep-learning?specialization=deep-learning)
### Week 1 Introduction to Deep Learning
   - [x] 1.1 Welcome
   - [x] 1.2 What is a Neural Network
   - [x] 1.3 Supervised Learning with Neural Networks
   - [x] 1.4 Why is Deep Learning taking off
   - [x] 1.5 About this Course
   - [ ] 1.6 Geoffrey Hinton Interview


### Week 2 Neural Networks Basics
#### 2.0 Logistic Regression as Neural Network
   - [x] 2.0.1 Binary Classification
   - [x] 2.0.2 Logistic Regression
   - [x] 2.0.3 Logistic Regression Cost Function
   - [x] 2.0.4 Gradient Descent
   - [x] 2.0.5 Derivatives
   - [x] 2.0.6 More Derivative Examples
   - [x] 2.0.7 Computation Graph
   - [x] 2.0.8 Derivatives with a Computation Graph
   - [x] 2.0.9 Logistic Regression Gradient Descent
   - [x] 2.0.10 Gradient Descent on m Examples

#### 2.1 Python and Vectorization
   - [x] 2.1.1 Vectorization
   - [x] 2.1.2 More Vectorization Examples
   - [x] 2.1.3 Vectorizing Logistic Regression
   - [x] 2.1.4 Vectorizing Logistic Regression's Gradient Output
   - [x] 2.1.5 Broadcasting in Python
   - [x] 2.1.6 A Note on Python Numpy Vectors
   - [x] 2.1.7 Quick tour of Jupyter iPython Notebooks
   - [x] 2.1.8 Explanation of Logistic Regression Cost Function (Optional)
   - [ ] 2.1.9 Pieter Abbeel Interview
   
### Week 3 Shallow Neural Networks
   - [ ] 3.1 Neural Networks Overview
   - [ ] 3.2 Neural Network Representation
   - [ ] 3.3 Computing a Neural Network's Output
   - [ ] 3.4 Vectorizing Across Multiple Examples
   - [ ] 3.5 Explanation for Vectorized Implementation
   - [ ] 3.6 Activation Functions
   - [ ] 3.7 Why do you need Non-Linear Activation Functions
   - [ ] 3.8 Derivatives of Activation Functions
   - [ ] 3.9 Gradient Descent for Neural Networks
   - [ ] 3.10 Backpropagation Intuition (Optional)
   - [ ] 3.11 Random Initialization
   - [ ] 3.12 Ian Goodfellow Interview

### Week 4 Deep Neural Networks
   - [ ] 4.1 Deep L-layer Neural 
   - [ ] 4.2 Forward Propagation in a Deep 
   - [ ] 4.3 Getting your Matrix Dimensions 
   - [ ] 4.4 Why Deep Representations
   - [ ] 4.5 Building Blocks of Deep Neural Networks
   - [ ] 4.6 Forward and Backward Propagation
   - [ ] 4.7 Parameters vs Hyperparameters
   - [ ] 4.8 What does this have to do with the brain
   
   
